Rida Faraz <br>
faraz@usc.edu
## CAIS++ Winter Curriculum Project: Sarcasm Detection in News Headlines Using NLP

### Summary
My project focuses on finetuning existing NLP models to aid in the task of sarcasm detection. With the growing influence of the internet in our lives, news articles and posts have become a lot of people's main source of information. Recognizing whether some of these sources are informational or serve as biased information or propaganda is crucial before trusting and formulating opinions on issues, and recognizing sarcasm helps in understanding the intent behind the publication. Moving beyong news articles, sarcasm detection is important in understanding natural human language. As a result, I aim to **improve the accuracy of a finetuned NLP deep learning network** in order to reliably detect sarcasm in the written information around us. 

### Dataset
The dataset I used to train my model was Kaggle's **News Headlines Dataset For Sarcasm Detection** data set. With over 28,000 entries, the data set's columns include the news headline, the article URL, and a value denoting its sarcasm (1 for sarcastic and 0 for not sarcastic). There was not a lot of processing that had to be done, as the data was designed specifically for the task the model was trying to achieve. The data covered a variety of articles, and it provided a strong training set for the task of sarcasm detection. It also had a relatively even split (49-51) between data items that were sarcastic and not sarcastic. After converting the JSON file into a dataframe and tokenizing the data using the XLNet tokenizer and Keras padding function, the model was ready to train.

### Model Development & Training
To train the model, I decided to take the finetuning approach. In the past, I had worked with BERT, which was a very popular model for its ability to simplify training for specific NLP tasks. Instead of BERT, I decided to try finetuning the pre-trained XLNet model for the task of sarcasm detection. According to other researchers, XLNet performed better than BERT in multiple categories, so with my goal of optimizing accuracy, it was a good option.  
The optimizer used was AdamW with a batch size of 32, weight decay rate of 0.01, and learning rate of 2e<sup>-5</sup>, and 4 epochs were used for training. The training process took over an hour, checking a validation set at each epoch, but the model performed extremely well. <br>
<br>
**Validation Accuracy: 0.9259** <br>

### Discussion
Overall, I believe that the model was successful. The data set was suited well for the task, providing a large amount of data to train the model and an even distribution over the classification bins. Using the advantages of finetuning pretrained NLP models, I was able to achieve a high accuracy score for a RNN that detects sarcasm in headlines. Amongst other approaches, I believe deep learning was the best approach to a sarcasm detection task, as sarcasm relies heavily on context. Given that the RNN has the ability to use self-attention and optimizers like AdamW, it reads context much better than classical ML methods would, making it optimal for this task. <br>
I think that this model can be very helpful in sarcasm detection, but it is limited since it hasn't been trained for other contexts. At the moment, we know it performs well when it comes to news headlines, but it is uncertain whether day to day conversation would have the same results since there may be different patterns in our regular speech that the model might not consider. Besides the task at hand, the ability to finetune any model for a specific task is also an important process that should not be overlooked. In the future, I plan on continuing to enhance my ability to finetune models based on what I learned throughout this project. <br>
Going forward, I would also want to try working with other pretrained models. XLNet was just one of many, so it would be interesting to see how different pretrained models perform under the same circumstances. Other than that, I also want to try working with other data sets, since my model is solely trained for sarcasm detection in news headlines. Recognizing the differences in language in the media versus launguage in casual conversation would be valuable in truly being able to train models to detect sarcasm in everyday speech. 
